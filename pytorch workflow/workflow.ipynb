{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn # contains all of pytorchs building block.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data (preparing and loading)\n",
    "\n",
    "Can be anything in ml\n",
    "\n",
    "* Excels speadsheet\n",
    "* Images and videos\n",
    "* Audio \n",
    "* DNA\n",
    "\n",
    "\n",
    "Ml it's a game in two parts\n",
    "* Get the data into a numberical representation\n",
    "* Build a model to learn the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000],\n",
      "        [0.0200],\n",
      "        [0.0400],\n",
      "        [0.0600],\n",
      "        [0.0800],\n",
      "        [0.1000],\n",
      "        [0.1200],\n",
      "        [0.1400],\n",
      "        [0.1600],\n",
      "        [0.1800]])\n",
      "tensor([[0.3000],\n",
      "        [0.3140],\n",
      "        [0.3280],\n",
      "        [0.3420],\n",
      "        [0.3560],\n",
      "        [0.3700],\n",
      "        [0.3840],\n",
      "        [0.3980],\n",
      "        [0.4120],\n",
      "        [0.4260]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some \"know\" data using LINEAR REGRESSION\n",
    "\n",
    "\n",
    "\n",
    "# Create *know* parameters\n",
    "weight = 0.7 # B\n",
    "bias = 0.3 # A\n",
    "\n",
    "# Create\n",
    "X = torch.arange(0, 1, 0.02).unsqueeze(dim = 1)\n",
    "y = weight * X + bias\n",
    "\n",
    "print(X[:10]),print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a train/test split\n",
    "\n",
    "train_split = int(0.8 * (len(X)))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "print(len(X_train)), print(len(y_train)), print(len(X_test)), print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch model builds essentials\n",
    "* torch.nn -> contains all of the buildings for computuional graphs\n",
    "* torch.nn.Parameter -> what parameters should our model try and learn\n",
    "* torch.nn.Module -> the base class for all neural netowrks\n",
    "* torch.optim -> this where the optimizers in Pytorch live, helo with gradient descent\n",
    "* def forward -> Defines what happens in the forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions using `torch.inference_mode()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3982],\n",
      "        [0.4049],\n",
      "        [0.4116],\n",
      "        [0.4184],\n",
      "        [0.4251],\n",
      "        [0.4318],\n",
      "        [0.4386],\n",
      "        [0.4453],\n",
      "        [0.4520],\n",
      "        [0.4588]])\n",
      "tensor([[0.8600],\n",
      "        [0.8740],\n",
      "        [0.8880],\n",
      "        [0.9020],\n",
      "        [0.9160],\n",
      "        [0.9300],\n",
      "        [0.9440],\n",
      "        [0.9580],\n",
      "        [0.9720],\n",
      "        [0.9860]])\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(1,))\n",
    "        self.bias = nn.Parameter(torch.randn(1,))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weight * x + self.bias\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = LinearRegression()\n",
    "\n",
    "with torch.inference_mode(): # or we can use the .no_grad()\n",
    "    y_preds = model_0(X_test)\n",
    "print(y_preds)\n",
    "print(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "in our case, our predictions be so poor, but how we can know that's it's a poor or better predictions, we use the loss funtions to meansure that and after use the optimizer to adjust these values, in these case we gonna use the MAE loss functiom (L1loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "\n",
    "# optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr =0.01) # lr it's the learning rate, how our pred it's 4 numbers after the ., when we use 0.01 it's 2 numbers, so a medium chagnes, if we put 0.1 will update a big changes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a training and testing loop\n",
    "Thing need in a training loop:\n",
    "0. Loop trough the data\n",
    "1. Forward pass to make predictions\n",
    "2. Calculate loss, compare forward pass to the true labels\n",
    "3. Optimizer zero grad\n",
    "4. Loss backward (backpropagation)\n",
    "5. Optimizer step (**gradient descent**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "A loss function foi de: 0.0089\n",
      "Os novos parametros são:\n",
      "Nome: weight, Parameter containing:\n",
      "tensor([0.6990], requires_grad=True)\n",
      "Nome: bias, Parameter containing:\n",
      "tensor([0.3093], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 0 loop trought the data\n",
    "epochs = 10000 # épocas\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()  # Set to the train mode\n",
    "    y_pred = model_0(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)  # Calcule the loss function (predicions with the real labels)]\n",
    "    optimizer.zero_grad() # The gradient turns 0 to calculate new grad\n",
    "    loss.backward() # Calculate the gradient\n",
    "    optimizer.step() # Update the parameters\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"A loss function foi de: {loss:.4f}\")\n",
    "\n",
    "model_0.eval()\n",
    "print(f\"Os novos parametros são:\")\n",
    "for nome, parametro in model_0.named_parameters():\n",
    "    print(f\"Nome: {nome}, {parametro}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test loss is: 0.0084\n"
     ]
    }
   ],
   "source": [
    "# testing code\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds_new = model_0(X_test)\n",
    "    loss = loss_fn(y_preds_new, y_test)\n",
    "print(f\"The test loss is: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model in PyTorch\n",
    "There are three main methods you should about for saving and loading models in torch\n",
    "\n",
    "1. `torch.save()` allow you save a pytorch object in python's pickle format\n",
    "2. `torch.load()` allows you load a saved PyTorch object\n",
    "3. `torch.nn.Module.load_state_dict()` allows you to load a model saved state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path in Models\\01_pytorch_workflow_model_0.pth\n"
     ]
    }
   ],
   "source": [
    "# Saving\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models directory\n",
    "MODEL_PATH = Path(\"Models\")\n",
    "MODEL_PATH.mkdir()\n",
    "\n",
    "# Create models save path\n",
    "\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Save in a state dict\n",
    "print(f\"Save path in {MODEL_SAVE_PATH}\")\n",
    "torch.save(model_0.state_dict(), MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
